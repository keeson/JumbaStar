"""
#========================================================================
# The goal of the assignment is to understand gini index and decision trees.
#
# TODO: Implement the functions. Add 2 unit test cases for each function.
# Submit: hw7.py, hw7_unittest.py
#========================================================================
#Question 1:
# Given a class list, calculate gini index                    (2 points)
# Unit test case (2 nos)                                      (1 point)

# Input:    class_list - sample in unit test file
# Output:   Gini index - float
#========================================================================
"""
def compute_gini_index(class_list):
    """Given a list of classes returns the gini index

    Input: a list of classes
    Output: a real (gini index)
    """
    book = {}
    length = float(len(class_list))
    output = 0
    for i in class_list:
        if i in book:
            book[i] += 1.0
        else:
            book[i] = 1.0
    for j in book.keys():
        temp = float(book[j]/length)
        book[j] = temp
        output += temp * float((1 - temp))
    return float(output)


"""
#========================================================================
# Question 2:
# Given a data set and the index of a numerical attribute, output the
# best split using the binary splitting algorithm discussed     (2 points)
# Unit test case - 2 nos                                        (1 point)
#
# Input:    The data set with numerical values for the attributes
#           Index of the attribute (see sample in unit test)
# Output:   The attribute value that gives the best split (float)
# Hint:     Compute information gain using gini index for every split
#========================================================================
"""
def findinside(data, attribute_index):
    """
    Find what is inside the tuple.
    """
    out = []
    for i in data:
        out.append(i[0])
    return out

def best_attribute_split(data, attribute_index):
    """ Compute the best value to split on.
    Input:
        data, (subset of the dataset)
        attribute_index (integer)
    Return: value

    """
    data = sorted(data, key=lambda x: x[1])
    best = 0
    amount = 0.0
    total = []
    for member in sorted(data, key=lambda x: x[1]):
        total.append(member[0])

    for i in range(0, len(data)):
        one = total[0: i+1]
        two = total[i+1: len(total)]

        temp = compute_gini_index(total) - float((i+1))/float(len(data))\
            *float(compute_gini_index(one)) - float((len(data) - i - 1))\
            /float(len(data))*float(compute_gini_index(two))

        if float(temp) >= amount:
            best = i
            amount = float(temp)
    return data[best][attribute_index]


"""
#========================================================================
# Question 3:
# Given a tree and a test observation return the prediction     (3 points)
# Use the example as a guide. Write your own tree and test observation in your
# unit test case                                                (1 point)
# Input:    x - test observation
#           tree - a decision tree
# Output:   The prediction for the observation
#========================================================================
"""
def tree_prediction(x, tree):
    """
    Input: test observation, tree
    Output: prediction for the target variable"""
    word = x
    newtree = tree
    current = {}
    node = [y for y in newtree.keys()][0]
    while type(node) != str:
        index = word[node]

        current = newtree[node][index]
        newtree = current
        if type(newtree) == str:
            return newtree
        node = [x for x in newtree.keys()][0]
    return newtree





